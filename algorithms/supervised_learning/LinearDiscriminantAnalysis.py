"""
Linear Discriminant Analysis Classifier
"""

# Author: Zachary B. Murphy


import numpy as np

class LinearDiscriminantAnalysisClassifier():
    """Linear Discriminant Analysis Classifier
    
    A binary classifier with a linear decision boundary,generated by fitting a
    sigmoid function to a training dataset and iteratively optimizing a set of 
    weights via gradient descent.
    
    Parameters
    ----------
    solution_technique : string, optional (default=2.0)
        Method of obtaining the discriminant function used for classification.
        Possible values:
            - "gaussian" :
                
            - "eigenvalue" :
          
        
        """
    def __init__(self, solution_technique = "coefficient_computation"):
        self.solution_technique = solution_technique
        
    def _compute_covariance(self, Xtrain):
        """Function to get unbiased covariances from a dataset.
           
         Parameters
         ----------
        Xtrain : array-like, shape (n_samples, n_features)
            Training data.
            
        Returns
        ----------
        covariance : array, shape (n_features, n_features)
                    A covariance matrix
         """
        covariance = np.cov(Xtrain.T, bias=False)
        return covariance
    
    def _compute_probability_vector(self, ytrain):
        """Get prior probabilities for each class.
           
         Parameters
         ----------
         ytrain : array, shape (n_samples,)
            Target values.
            
        Returns
        ----------
        self: A trained classifier object with Xtrain and ytrain stored as 
        attributes.
         """
        _,  y_t = np.unique(ytrain, return_inverse=True)  # non-negative ints
        probabilities = np.bincount(y_t) / float(len(ytrain))
        return probabilities
    
    def _compute_class_averages(self, Xtrain, ytrain):
        """Get averages of all features for each class in the training 
        dataset.
           
         Parameters
         ----------
         Xtrain : array-like, shape (n_samples, n_features)
            Training data.
         ytrain : array, shape (n_samples,)
            Target values.
            
        Returns
        ----------
        means: array, shape (n_classes, n_features)
        
        A vector containing the average values of each feature for each class.
         """
        classes, y = np.unique(ytrain, return_inverse=True)
        cnt = np.bincount(ytrain)
        means = np.zeros(shape=(len(classes), Xtrain.shape[1]))
        np.add.at(means, ytrain, Xtrain)
        means /= cnt[:, None]
        return means
    
    def _compute_global_covariance(self, Xtrain, ytrain):
        """Get a global covariance matrix, weighted by the probabilities that 
        each class is observed in the dataset.
           
         Parameters
         ----------
         Xtrain : array-like, shape (n_samples, n_features)
            Training data.
         ytrain : array, shape (n_samples,)
            Target values.
            
        Returns
        ----------
        covariance : array, shape (n_features, n_features)
                    A covariance matrix.
         """
        classes = np.unique(ytrain)
        cov = np.zeros(shape=(Xtrain.shape[1], Xtrain.shape[1]))
        probabilities = _compute_probability_vector(ytrain)
        for idx, group in enumerate(classes):
            Xg = Xtrain[ytrain == group, :]
            cov += probabilities[idx] * np.atleast_2d(_compute_covariance(Xg))
        return cov
    
    def train(self, Xtrain, ytrain):
        """Fits Linear Discriminant Analysis to the given data using the
        desired solution method. Fitting LDA involves computation of 
        various coefficients and intercept terms.
           
         Parameters
         ----------
         Xtrain : array-like, shape (n_samples, n_features)
            Training data.
         ytrain : array, shape (n_samples,)
            Target values.
            
        Returns
        ----------
        self: A trained classifier object with computed coefficients and 
        intercepts that depend on the value of the solution_technique 
        parameter.
         """
        self.prior_probs = self._compute_probability_vector(ytrain)
        self.class_averages = self._compute_class_averages(Xtrain, ytrain)
        if self.solution_technique == "gaussian":
            self.intercept = np.log(self.prior_probs)-0.5*()
        
        #else if self.solution_technique=="eigenvalue":
            
        else:
            print("Solution technique is not recognized. Please use 'linear_discriminant' or 'eigenvalue'.")
        return self
    
    
    def predict(self, Xtest):
         """Perform classification on an array of test vectors called Xtest.
        The predicted class ypred for each sample in X is returned.
        
        Parameters
        ----------
        Xtest : array-like, shape = [n_samples, n_features]
        
        Returns
        -------
        ypred : array, shape = [n_samples]
        """
        
# =============================================================================
# Testing section    
# =============================================================================
if __name__ == "__main__":
    import pandas as pd
    from sklearn.preprocessing import StandardScaler

    data=pd.read_csv("C:/Users/zmurp/github/Machine_Learning_Algorithms/datasets/diabetes.csv")
    data.median()
    dataset = data.fillna(data.median())
    X = dataset.iloc[:500, 0:8].values
    ytrain = dataset.iloc[:500, 8].values
    scaler = StandardScaler()
    Xtrain = scaler.fit_transform(X)

    Xtest=scaler.fit_transform(dataset.iloc[500:, 0:8].values)
    ytest=dataset.iloc[500:, 8].values
    
    covar = LinearDiscriminantAnalysisClassifier()._compute_class_averages(Xtrain=Xtrain, ytrain=ytrain)
    print(covar)

    