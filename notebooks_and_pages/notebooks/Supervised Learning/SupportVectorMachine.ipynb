{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "The diagram below shows a two-dimensional dataset with two classes. When we construct a classification algorithm, what might the decision boundary look like that best separates the classes? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One might choose a line that is halfway between the classes, so that the space between the line and the nearest observations for each class has some \"wiggle room\". This wiggle room is referred to as a <strong>margin</strong>, and any classifier that tries to create the largest possible margin between the decision boundary and the classes is referred to as a <strong>Maximum Margin Classifier</strong>. The most well-known such classifier is referred to as a <strong>Support Vector Classifier</strong>. Support Vector Classifiers operate by constructing a boundary called a \"hyperplane\" between opposing classes of data. It uses the values of the feature vectors closest to the hyperplane to maximimize the margin. These unique feature vectors are called the <strong>support vectors</strong>, and are what give the algorithm its name.\n",
    "\n",
    "Conceptually, the SVC is a relatively straightforward and intuitive concept. The algorithm itself is an example of a convex optimization problem. We now dive into the mathematical concepts behind the SVC before getting to the code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background on Support Vector Classifiers\n",
    "\n",
    "Consider the diagram below. The red and blue dots represent observations from two distinct classes in a binary classification problem. the hollow red and blue dots represent the support vectors mentioned earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"svm1.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"svm1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Support Vector Classifier\n",
    "\n",
    "The support vecot classifier algorithm that we will be implementing will be using an optimzation technique called sequential minimal optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxopt as cvx\n",
    "\n",
    "class SupportVectorClassifier:\n",
    "    \n",
    "    def __init__(self, C=1, kernel='linear', power=4, gamma=None, coef=4):\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "        self.power = power\n",
    "        self.gamma = gamma\n",
    "        self.coef = coef\n",
    "        self.lagr_multipliers = None\n",
    "        self.support_vectors = None\n",
    "        self.support_vector_labels = None\n",
    "        self.intercept = None\n",
    "\n",
    "svm = SupportVectorClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll explain the attributes that we have created for the SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_kernel:\n",
    "    pass\n",
    "\n",
    "\n",
    "def polynomial_kernel:\n",
    "    pass\n",
    "\n",
    "\n",
    "def gaussian_kernel:\n",
    "    pass\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
